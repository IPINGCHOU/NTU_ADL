{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/disk2/iping/NTU_ADL/ADL_hw1/hw1_sample_code/src\")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from argparse import Namespace\n",
    "from typing import Tuple, Dict\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import Seq2SeqDataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_path, emb_dim, enc_hid_dim, enc_layers, dec_hid_dim, enc_dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            embedding = pickle.load(f)\n",
    "        embedding_weight = embedding.vectors\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weight)\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.enc_layers = enc_layers\n",
    "        self.enc_dropout = enc_dropout\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size = emb_dim,\n",
    "                          hidden_size = enc_hid_dim,\n",
    "                          num_layers = enc_layers,\n",
    "                          bidirectional = True,\n",
    "                          batch_first = False)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(enc_dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        return outputs, hidden    \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_path, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dec_dropout, dec_num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            embedding = pickle.load(f)\n",
    "        embedding_weight = embedding.vectors\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weight)\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, dec_hid_dim, num_layers = dec_num_layers, batch_first = False)\n",
    "#         self.fc_out = nn.Linear(dec_hid_dim + emb_dim, output_dim)\n",
    "        self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dec_dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "\n",
    "        output, hidden = self.rnn(embedded, hidden.unsqueeze(0))\n",
    "\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "#         embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        \n",
    "#         prediction = self.fc_out(torch.cat((output, embedded), dim = 1))\n",
    "\n",
    "        prediction = self.fc_out(output)\n",
    "\n",
    "        return prediction, hidden.squeeze(0)\n",
    "\n",
    "class Seq2Seq(pl.LightningModule):\n",
    "    def __init__(self, hparams) -> None:\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index = self.hparams.ignore_idx)\n",
    "        self.encoder = Encoder(hparams.embedding_path,\n",
    "                               hparams.emb_dim,\n",
    "                               hparams.enc_hid_dim,\n",
    "                               hparams.enc_num_layers,\n",
    "                               hparams.dec_hid_dim,\n",
    "                               hparams.enc_dropout)\n",
    "        self.decoder = Decoder(hparams.embedding_path,\n",
    "                               hparams.output_dim,\n",
    "                               hparams.emb_dim,\n",
    "                               hparams.enc_hid_dim,\n",
    "                               hparams.dec_hid_dim,\n",
    "                               hparams.dec_dropout,\n",
    "                               hparams.dec_num_layers)\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "                \n",
    "        if trg != 'test':\n",
    "            input = trg[0,:]\n",
    "            trg_len = trg.shape[0]\n",
    "\n",
    "            outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to('cuda:0')\n",
    "            encoder_outputs, hidden = self.encoder(src)\n",
    "            for t in range(1, trg_len):\n",
    "                output, hidden = self.decoder(input, hidden)\n",
    "                outputs[t] = output\n",
    "                teacher_force = random.random() > teacher_forcing_ratio\n",
    "                top1 = output.argmax(1) \n",
    "                input = trg[t] if teacher_force else top1\n",
    "        else:\n",
    "            input = torch.ones(batch_size).to(device = 'cuda:0', dtype=torch.int64)\n",
    "            trg_len = 80\n",
    "            outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to('cuda:0')\n",
    "            encoder_outputs, hidden = self.encoder(src)\n",
    "            for t in range(1, trg_len):\n",
    "                output, hidden = self.decoder(input, hidden)\n",
    "                outputs[t] = output\n",
    "                input = output.argmax(1) \n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _unpack_batch(self, batch) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        try:\n",
    "            return batch['text'], batch['summary']\n",
    "        except:\n",
    "            return batch['text']\n",
    "\n",
    "    def _calculate_loss(self, output, trg) -> torch.tensor:\n",
    "        # TODO\n",
    "        # calculate the logits\n",
    "        # plz use BCEWithLogit\n",
    "        # adjust pos_weight!\n",
    "        # MASK OUT PADDINGS' LOSSES!\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        \n",
    "        loss = self.criterion(output, trg)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_nb) -> Dict:\n",
    "        x, y = self._unpack_batch(batch)\n",
    "        x = x.permute(1,0)\n",
    "        y = y.permute(1,0)\n",
    "        output = self.forward(x,y)\n",
    "        loss = self._calculate_loss(output, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb) -> Dict:\n",
    "        x, y = self._unpack_batch(batch)\n",
    "        x = x.permute(1,0)\n",
    "        y = y.permute(1,0)\n",
    "        output = self.forward(x,y)\n",
    "        loss = self._calculate_loss(output, y)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs) -> Dict:\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def _load_dataset(self, dataset_path: str) -> Seq2SeqDataset:\n",
    "        with open(dataset_path, 'rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self._load_dataset(self.hparams.train_dataset_path)\n",
    "        return DataLoader(dataset, \n",
    "                          self.hparams.batch_size, \n",
    "                          shuffle=True,\n",
    "                          collate_fn=dataset.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self._load_dataset(self.hparams.valid_dataset_path)\n",
    "        return DataLoader(dataset, \n",
    "                          self.hparams.batch_size, \n",
    "                          collate_fn=dataset.collate_fn)\n",
    "    \n",
    "class MyPrintingCallback(pl.Callback):\n",
    "    \n",
    "    def on_validation_start(self, trainer, pl_module):\n",
    "        print('validation starts')\n",
    "        \n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        print('validation end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/disk2/iping/NTU_ADL/ADL_hw1/data'\n",
    "hparams = Namespace(**{\n",
    "    'embedding_path': data_path + \"/embedding_seq2seq.pkl\",\n",
    "    'train_dataset_path': data_path + \"/train_seq2seq.pkl\",\n",
    "    'valid_dataset_path': data_path + \"/valid_seq2seq.pkl\",\n",
    "    \n",
    "    'ignore_idx': 0,\n",
    "    'batch_size': 64,\n",
    "    \n",
    "    'emb_dim' : 300,\n",
    "    'enc_hid_dim' : 512,\n",
    "    'enc_num_layers' : 1,\n",
    "    'enc_dropout' : 0,\n",
    "    \n",
    "    'output_dim' : 97513,\n",
    "    'dec_hid_dim' : 512,\n",
    "    'dec_dropout' : 0,\n",
    "    'dec_num_layers': 1,\n",
    "\n",
    "    'lr': 1e-04,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64ec8bb17304dfc92da2cb71fc219d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=313.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_checkpoint = \"/disk2/iping/NTU_ADL/ADL_hw1/seq2seq_model/\"\n",
    "PATH_checkpoint += \"model_drop0_lr1e04_noembed_{epoch:02d}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=PATH_checkpoint,\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='avg_val_loss',\n",
    "    mode='min',\n",
    "    prefix=''\n",
    ")\n",
    "\n",
    "seq2seq = Seq2Seq(hparams)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=20, checkpoint_callback=checkpoint_callback)\n",
    "trainer.fit(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "PATH_checkpoint = \"/disk2/iping/NTU_ADL/ADL_hw1/seq2seq_model/\"\n",
    "PATH_checkpoint += \"best_seq2seq_abstractive_model.ckpt\"\n",
    "seq2seq = Seq2Seq.load_from_checkpoint(PATH_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(97513, 300)\n",
       "    (rnn): GRU(300, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(97513, 300)\n",
       "    (rnn): GRU(300, 512)\n",
       "    (fc_out): Linear(in_features=512, out_features=97513, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Test:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 1250/1250 [04:49<00:00,  4.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# if pl test doesnt work\n",
    "with open(data_path + \"/valid_seq2seq.pkl\", 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "test_loader = DataLoader(dataset, \n",
    "                         16, \n",
    "                         collate_fn=dataset.collate_fn)\n",
    "device ='cuda:0'\n",
    "print(device)\n",
    "trange_test = tqdm(enumerate(test_loader), total=len(test_loader), desc = 'Test')\n",
    "ans = []\n",
    "seq2seq.train(False)\n",
    "log_softmax = nn.LogSoftmax(dim=-1)\n",
    "for z, (batch) in trange_test:\n",
    "    x,_ = seq2seq._unpack_batch(batch)\n",
    "    x = x.to(device)\n",
    "    x = x.permute(1,0)\n",
    "    seq2seq.to(device)\n",
    "    output = seq2seq.forward(x, 'test', 0)\n",
    "    output = log_softmax(output)\n",
    "    output = torch.argmax(output.permute(1,0,2), axis = 2)    \n",
    "    output = output.type(torch.int64).tolist()\n",
    "    ans.extend(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/disk2/iping/NTU_ADL/ADL_hw1/data'\n",
    "with open(data_path + \"/embedding_seq2seq.pkl\", 'rb') as f:\n",
    "    embed_dataset = pickle.load(f)\n",
    "with open(data_path + \"/valid_seq2seq.pkl\", 'rb') as f:\n",
    "    valid_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ans_jsonl = []\n",
    "for data, a in zip(valid_dataset, ans):\n",
    "    now_sent = ''\n",
    "    for i in a:\n",
    "        if i != 2:\n",
    "            now_vocab = embed_dataset.vocab[i]\n",
    "            now_sent = now_sent + now_vocab + ' '\n",
    "        else:\n",
    "            now_sent = now_sent[:-6]\n",
    "            now_sent = now_sent[7:]\n",
    "            break\n",
    "    ans_jsonl.append({'id':data['id'], 'predict': now_sent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "PATH_save = \"/disk2/iping/NTU_ADL/ADL_hw1/for_testing/\"\n",
    "filename_save = 'output_seq2seq_lr1e04_nounk_noheader'\n",
    "with open(PATH_save+filename_save+'.jsonl', 'w') as outfile:\n",
    "    for entry in ans_jsonl:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
